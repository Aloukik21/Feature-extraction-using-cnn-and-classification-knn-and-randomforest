{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment_3 Smart health\n",
    "# Name: Aloukik Aditya\n",
    "# Student_ID: 1115290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.models import Model \n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import  to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "import sys\n",
    "import os\n",
    "#import cv2 \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage import data, io, filters\n",
    "from skimage.transform import rescale\n",
    "import time\n",
    "# from tensorflow.keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "kerasBKED = os.environ[\"KERAS_BACKEND\"] \n",
    "print(kerasBKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob#---------------------------------------------this helps in reading all the images\n",
    "Abdomen = glob.glob('DS_NN/DS/Abdomen_CT*.jpeg')\n",
    "Chest = glob.glob('DS_NN/DS/Chest_CT*.jpeg')\n",
    "Head = glob.glob('DS_NN/DS/Head_CT*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(Abdomen))#------------------ checking the number of files of each class\n",
    "print(len(Chest))\n",
    "print(len(Head))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this section will create the training and testing sets (very important) ratio is 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.clear()\n",
    "labels = []\n",
    "labels.clear()\n",
    "num_classes = 3\n",
    "\n",
    "for i in Abdomen:   #------------------------------------------------------------------\n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', #----------------- using grayscale image\n",
    "    target_size= (32,32))#--------------------------------------------------using dimension as 32 by 32\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)#---------------------------------------now this the label for abdomen section which is zero\n",
    "for i in Chest:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', \n",
    "    target_size= (32,32))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "for i in Head:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='grayscale', \n",
    "    target_size= (32,32))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(2)\n",
    "\n",
    "data = np.array(data)#----------------------- it contain all the images of abdomen, chest and head\n",
    "labels = np.array(labels)#-------------------------this contian all the labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.4)#--------------it will randmoly split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 32, 32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape#-- checking dimension, but our model wont accept this type of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train,(-1, 32, 32 , 1))#---------so reshaping model\n",
    "X_test = np.reshape(X_test,(-1, 32, 32 , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 1, 1, 0, 1, 2, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 1, 0, 2, 2, 2, 0, 0, 0, 2, 0, 1,\n",
       "       0, 0, 0, 2, 2, 1, 2, 0, 0, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 2, 0, 1,\n",
       "       2, 0, 0, 0, 1, 1, 1, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 2, 2, 2, 0, 2, 0, 1, 0, 1, 2, 1, 2, 1, 2, 1, 1, 2,\n",
       "       1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 0, 2, 1, 0, 1, 1, 0,\n",
       "       1, 2, 1, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 2, 0, 1, 2, 1, 0, 2, 2,\n",
       "       0, 1, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 32, 32, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape#-----------------updated shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_encoded = keras.utils.to_categorical(ytrain, num_classes)#-----------------------preprocessing data here\n",
    "ytest_encoded = keras.utils.to_categorical(ytest, num_classes)\n",
    "\n",
    "X_train = X_train.astype(np.float32)#---------------------normalizaing the data\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 32, 32, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution neural network starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureLayer1=[Conv2D(64, (3, 3), padding='same',input_shape=X_train.shape[1:]),\n",
    "               Activation('relu'),\n",
    "               Conv2D(64, (3, 3), padding='same'),#-------------all the the cov layers attain features \n",
    "               Activation('relu'),\n",
    "               MaxPooling2D(pool_size=(2, 2)),\n",
    "               Dropout(0.25)]\n",
    "\n",
    "featureLayer2=[Conv2D(128, (3, 3), padding='same'),\n",
    "               Activation('relu'),\n",
    "               Conv2D(128, (3, 3), padding='same'),\n",
    "               Activation('relu'),\n",
    "               MaxPooling2D(pool_size=(2, 2)),\n",
    "               Dropout(0.25)]\n",
    "\n",
    "featureLayer3=[Conv2D(256, (3, 3), padding='same'),\n",
    "               Activation('relu'),\n",
    "               Conv2D(256, (3, 3), padding='same'),\n",
    "               Activation('relu'),\n",
    "               Conv2D(256, (3, 3), padding='same'),\n",
    "               Activation('relu'),\n",
    "               MaxPooling2D(pool_size=(2, 2)),\n",
    "               Dropout(0.25)]\n",
    "\n",
    "fullConnLayer=[Flatten(),\n",
    "               Dense(1024),\n",
    "               Activation('relu'),\n",
    "               Dropout(0.5),\n",
    "               Dense(1024),\n",
    "               Activation('relu'),\n",
    "               Dropout(0.5)]\n",
    "\n",
    "classificationLayer=[Dense(num_classes),\n",
    "                     Activation('softmax')]\n",
    "\n",
    "model = Sequential(featureLayer1 + featureLayer2 + featureLayer3 + fullConnLayer + classificationLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (900, 32, 32, 1)\n",
      "900 train samples\n",
      "600 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')#----------checking dimentions\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,#---------------------------------compiling model here\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 1.1011 - accuracy: 0.3444 - val_loss: 1.0849 - val_accuracy: 0.5667\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.7051 - accuracy: 0.5722 - val_loss: 0.4885 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.4877 - accuracy: 0.6678 - val_loss: 0.4585 - val_accuracy: 0.6833\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.4827 - accuracy: 0.6467 - val_loss: 0.4584 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 1.2211 - accuracy: 0.5067 - val_loss: 1.0999 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 9s 324ms/step - loss: 1.0234 - accuracy: 0.4267 - val_loss: 0.9312 - val_accuracy: 0.5217\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.5110 - accuracy: 0.6789 - val_loss: 0.4275 - val_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.4516 - accuracy: 0.7533 - val_loss: 0.3327 - val_accuracy: 0.6717\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 10s 361ms/step - loss: 0.4017 - accuracy: 0.7989 - val_loss: 0.2827 - val_accuracy: 0.8100\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 10s 358ms/step - loss: 0.1699 - accuracy: 0.9244 - val_loss: 0.1628 - val_accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10#----------------------------------------performance of the model can be increased if epochs are increased\n",
    "history = model.fit(X_train, ytrain_encoded,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,#-----------------------------------------------------starting model here\n",
    "                    validation_data=(X_test, ytest_encoded),\n",
    "                    callbacks= [es_cb],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.16279882192611694\n",
      "Test accuracy: 0.9916666746139526\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, ytest_encoded, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5CB11550>\n",
      "1 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5CB38C50>\n",
      "2 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5CB38DA0>\n",
      "3 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF56048>\n",
      "4 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000019E5DF56198>\n",
      "5 <tensorflow.python.keras.layers.core.Dropout object at 0x0000019E5DF56320>\n",
      "6 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5DF564A8>\n",
      "7 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF56710>\n",
      "8 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5DF56860>\n",
      "9 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF56AC8>\n",
      "10 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000019E5DF56C18>\n",
      "11 <tensorflow.python.keras.layers.core.Dropout object at 0x0000019E5DF56DA0>\n",
      "12 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5DF56EB8>\n",
      "13 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF63160>\n",
      "14 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5DF632B0>\n",
      "15 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF63518>\n",
      "16 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000019E5DF63668>\n",
      "17 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF638D0>\n",
      "18 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000019E5DF63A20>\n",
      "19 <tensorflow.python.keras.layers.core.Dropout object at 0x0000019E5DF63BA8>\n",
      "20 <tensorflow.python.keras.layers.core.Flatten object at 0x0000019E5DF56E80>\n",
      "21 <tensorflow.python.keras.layers.core.Dense object at 0x0000019E5DF63E10>\n",
      "22 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF6C0B8>\n",
      "23 <tensorflow.python.keras.layers.core.Dropout object at 0x0000019E5DF6C1D0>\n",
      "24 <tensorflow.python.keras.layers.core.Dense object at 0x0000019E5DF6C2E8>\n",
      "25 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF6C518>\n",
      "26 <tensorflow.python.keras.layers.core.Dropout object at 0x0000019E5DF6C630>\n",
      "27 <tensorflow.python.keras.layers.core.Dense object at 0x0000019E5DF63C88>\n",
      "28 <tensorflow.python.keras.layers.core.Activation object at 0x0000019E5DF6C9E8>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Layers definitions\n",
    "from keras import backend as K#------------------------this will help to get all info of the layers which we habe in our model\n",
    "for l in range(len(model.layers)):\n",
    "    print(l, model.layers[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1=model.layers[0].input#------------selecting initial layer\n",
    "outputs_1=model.layers[26].output#------------according to question selelcting intermediate layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "# # feature extraction layer\n",
    "getFeature = K.function([inputs_1],\n",
    "                         [outputs_1])#----------------------------------getting features from this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_train = getFeature([X_train[:900], 0])[0]#-------------- we need to change to feed into KNN and RF using k function\n",
    "extracted_features_test = getFeature([X_test[:600], 0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = ytrain[:900]\n",
    "test_labels = ytest[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.18346983, ..., 0.        , 0.3027268 ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of getFeature function\n",
    "extracted_features_train[0]#-----------checking values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1024) (600, 1024) (900,) (600,)\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features_train.shape, extracted_features_test.shape, train_labels.shape, test_labels.shape)#----------cheking dimentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN starts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy:- 1.0 at K = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------------K nearest neighbour starts here-----------------------------#####\n",
    "from multiprocessing import Queue\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train = extracted_features_train\n",
    "y_train = train_labels\n",
    "X_test = extracted_features_test\n",
    "y_test = test_labels\n",
    "\n",
    "\n",
    "acc = []\n",
    "acc.clear()\n",
    "# Will take some time\n",
    "from sklearn import metrics\n",
    "for i in range(1,15):#---------------------------value of k = 1, 3 ,5, 7 included in this\n",
    "    KNN_model = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
    "    knn_prediction = KNN_model.predict(X_test)\n",
    "    acc.append(metrics.accuracy_score(y_test, knn_prediction))\n",
    "    \n",
    "plt.figure(figsize=(10,6))#---------------------------------------used to plot graph as mentioned in question\n",
    "plt.plot(range(1,15),acc,color = 'blue',linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('accuracy vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "print(\"Maximum accuracy:-\",max(acc),\"at K =\",acc.index(max(acc))+1)#------------- getting most optimal value of k and accuracy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KNN_filename = '1115290_KNN.pkl'\n",
    "# Open the file to save as pkl file#------------------saving model for KNN\n",
    "saved = open(KNN_filename, 'wb')\n",
    "pickle.dump(KNN_model, saved)\n",
    "# Close the pickle instances\n",
    "saved.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest starts below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False], 'max_features': [1, 3, 10],\n",
       "                         'n_estimators': [10, 20, 50]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################_--------------------------------Random forest starts here------------------###################################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"n_estimators\": [10, 20, 50]}\n",
    "rclf = RandomForestClassifier()\n",
    "rgclf = GridSearchCV(rclf, param_grid=parameters)\n",
    "rgclf.fit(extracted_features_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=1, n_estimators=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rclf = rgclf.best_estimator_\n",
    "rclf.fit(extracted_features_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++Printing Confusion matrix below+++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       194\n",
      "           1       1.00      1.00      1.00       198\n",
      "           2       1.00      1.00      1.00       208\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "Optimal parameteres  --------------> RandomForestClassifier(max_features=1, n_estimators=10)\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_RandomForest = rclf.predict(extracted_features_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score#-----------confusion matrix and optimal paramerts are shwon below\n",
    "print(\"++++++++++++++Printing Confusion matrix below+++++++++++++++\")\n",
    "print(classification_report(test_labels, predicted_RandomForest))\n",
    "a = rgclf.best_estimator_\n",
    "print(\"Optimal parameteres  -------------->\"  , a)\n",
    "print(\"Accuracy: {0}\".format(accuracy_score(test_labels, predicted_RandomForest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF_filename = '1115290_RandomForest.pkl'#------------------------saving random forest pkl file\n",
    "# Open the file to save as pkl file\n",
    "saved = open(RF_filename, 'wb')\n",
    "pickle.dump(rclf, saved)\n",
    "# Close the pickle instances\n",
    "saved.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------LOading models here-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models can be loaded from below sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded KNN model::  KNeighborsClassifier(n_neighbors=14)\n"
     ]
    }
   ],
   "source": [
    "KNN_m = open(KNN_filename, 'rb')\n",
    "Knn_load = pickle.load(KNN_m)\n",
    "print (\"Loaded KNN model:: \", Knn_load)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded RF model::  RandomForestClassifier(max_features=1, n_estimators=10)\n"
     ]
    }
   ],
   "source": [
    "RF_m = open(RF_filename, 'rb')\n",
    "RF_load = pickle.load(RF_m)\n",
    "print (\"Loaded RF model:: \", RF_load)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
